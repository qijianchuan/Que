---
title: 05 flume将数据导入到Hive
categories: 23 flume入门
tags: flume
---
我们已经了解了使用flume监听端口以及文件内容，本节将展示使用flume导入数据到hbase。

# 1 系统、软件以及前提约束

  * CentOS 7 64 工作站 作者的机子ip是192.168.100.200，请读者根据自己实际情况设置
  * 已完成flume安装并监听端口数据，flume的服务名称为a1  
https://www.jianshu.com/p/3e4f7db8080f

  * 已完成hive安装  
https://www.jianshu.com/p/755944f01fab

  * xshell客户端
  * 为去除权限对操作的影响，所有操作都以root进行

# 2 操作

  * 1 使用xshell登录到192.168.100.200
  * 2 启动hadoop

    
    
    cd /root/hadoop-2.5.2/sbin
    ./start-all.sh
    

  * 3 启动metastore  
cd /root/apache-hive-0.14.0-bin/bin  
./hive --service metastore

  * 4 修改flume-conf.properties

    
    
    a1.sources=r1
    a1.channels=c1
    a1.sinks=s1
    
    a1.sources.r1.type=netcat
    a1.sources.r1.bind=192.168.100.200
    a1.sources.r1.port=44444
    
    a1.sinks.s1.type=hive
    a1.sinks.s1.hive.metastore=thrift://192.168.100.200:9083
    a1.sinks.s1.hive.database=flume
    a1.sinks.s1.hive.table=t_user
    a1.sinks.s1.serializer=DELIMITED
    a1.sinks.s1.serializer.delimiter="\t"
    a1.sinks.s1.serializer.serdeSeparator='\t'
    a1.sinks.s1.serializer.fieldnames=user_id,user_name,age
    
    a1.channels.c1.type=memory
    a1.channels.c1.capacity=1000
    a1.channels.c1.transactionCapacity=100
    
    a1.sources.r1.channels=c1
    a1.sinks.s1.channel=c1
    

  * 5 拷贝jar包

    
    
    cp /root/apache-hive-0.14.0-bin/hcatalog/share/hcatalog/* /root/apache-flume-1.8.0-bin/lib/
    

  * 6 在hive中创建数据库和表

    
    
    cd /root/apache-hive-0.14.0-bin/bin
    ./hive
    >create database flume;
    >create table t_user(user_id int,user_name string, age int) clustered by(user_id) into 2 buckets stored as orc tblproperties("transactional"='true');
    

  * 5 通过nc【如果没有需要通过yum安装nc】向192.168.100.200的44444端口写入符合要求的数据  
nc 192.168.100.200 44444

  * 6 查看hive中表的数据

    
    
    cd /root/apache-hive-0.14.0-bin/bin
    ./hive
    >select * from flume.t_user;
    

至此，我们完成了flume导入数据到hive。

