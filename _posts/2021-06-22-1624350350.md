---
title: Hive之——Hive-hiveserver2-beeline
categories: 精通大数据系列
tags: Hadoop Hive
---
在Hadoop集群中任选一台服务器作为Hive的服务器。主要配置Hive，配置好后，启动该服务器的meterstore，并配置

    
    
    <!--配置使远程客户端连接Hive服务器bidev-cdh005-->
    <property>
        <name>hive.metastore.uris</name>
        <value>thrift://ip_or_host:9083</value>
    </property>

同时配置mysql的存储hive的元数据。

    
    
    #ps aux | grep metastore

能够找到相应的进程，有记录说明成功。  
成功后，将Hive服务器的相关Hive工具安装包复制到其他的hadoop节点上，有hive.metastore.uris这个配置，因此，可以其他的hadoop节点也可作为hive的客户端。

**#启动Hive的thriftServer即hiveserver2**

    
    
    nohup hive --service metastore >> /dev/null &    #后台方式启动hivemetastore
    nohup hive --service hiveserver2 /dev/null &      #后台方式启动hiveserver2

**#beeline的使用：**

前提：任何一个Hive客户端（hadoop节点）的Hiveserver2服务的开启，默认端口是10000，可以通过

    
    
    netstat -nltp | grep 10000  #判断这个Hiveserver2是否启动。也可以通过
    ps aux | grep HiveServer2   #（注意大小写，可以使用grep -i 不区分大小写）

在hive的bin目录下 启动beeline脚本./beeline后，再输入

    
    
    !connect jdbc:hive2://localhost:10000 userName password (先账号名 后密码)。

线上只要启动了HiveServer2,可以令username,password都为空登录，不过没有数据的查询权限。  
注意总结下Linux下直接登录Hive远程模式终端的方法。

    
    
    bin/beeline -u jdbc:hive2://
    bin/beeline -u jdbc:hive2://localhost:10000
    bin/beeline -u jdbc:hive2://localhost:10000 -n user -p password
    

-u : 指定元数据库的链接信息  
-n : 指定用户名  
-p : 指定密码

这里的用户名和密码可以是安装hadoop集群的用户名和密码。

**#另外还有一种方式也可以去连接：**

先执行

    
    
    ./bin/beeline

接着输入

    
    
    !connect jdbc:hive2://localhost:10000

然后按回车，然后输入用户名，这个用户名就是安装 hadoop 集群的用户名

