---
title: 基于HDP使用Flume实时采集MySQL中数据传到Kafka+HDFS或Hive
categories: 大数据动物园 Hive 大数据基础知识
tags: Flume MySQL Kafka HDFS Hive
---
**环境版本： HDP-2.5.3**  
**注意：HDP中Kafka broker的端口是6667，不是9092**  
如果只sink到kafka请看这篇：基于HDP使用Flume采集MySQL中数据传到Kafka

* * *

# 前言

有两种方式可以将数据通过flume导入hive中，一是直接sink到hive中，二是sink到hdfs中，然后在hive中建个外部表。直接sink到hive中相对麻烦一些，需要加入需要的jar包，而且hive表需要分桶、开启事务、保存为ORC格式。其实搞清楚了也不麻烦，但是本文中agent.sources.r1.type使用org.keedio.flume.source.SQLSource，传入的字段全变成了加上双引号的字符串，处理起来比较麻烦。所以我最终选用了sink到hdfs中，可以通过OpenCSVSerde去掉双引号。现给出了两种方案，各取所需吧。如有别的方式去掉双引号，欢迎下方留言。  

### 文章目录

  * 前言
  * 1.将所需jar包放入Flume安装目录lib下
  * 2.sink到hdfs
  *     * 2.1 编写mysql_kafka_hdfs.conf
    * 2.2 建外部表 

